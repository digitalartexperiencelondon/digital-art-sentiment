{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mevon-AI: Speech Emotion Recognition Demo",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8QcXQ_4POSt",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "### **<font> Emotion Recognizer </font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttDOvPzPPXky",
        "colab_type": "text"
      },
      "source": [
        "#◢ Mevon-AI - Recognize Emotions in Speech\n",
        "\n",
        "This program is for recognizing emotions from audio files generated in a customer care call center. A customer care call center of any company receives many calls from customers every day. Every call is recorded for analysis purposes. The program aims to analyse the  emotions of the customer and employees from these recordings. \n",
        "\n",
        "The emotions are classified into 6 categories: 'Neutral', 'Happy', 'Sad', 'Angry', 'Fearful', 'Disgusted', 'Surprised'\n",
        "\n",
        "Analysing the emotions of the customer after they have spoken with the company's employee in the call center can allow the company to understand the customer's behaviour and rate the performance of its employees accordingly.\n",
        "\n",
        "\n",
        "####**Credits:**\n",
        "\n",
        "* [Speech Emotion Recognition from Saaket Agashe's Github](https://github.com/saa1605/speech-emotion-recognition)\n",
        "* [Speech Emotion Recognition with CNN](https://towardsdatascience.com/speech-emotion-recognition-with-convolution-neural-network-1e6bb7130ce3)\n",
        "* [MFCCs Tutorial](http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/)\n",
        "* [UIS-RNN Fully Supervised Speaker Diarization](https://github.com/google/uis-rnn)\n",
        "* [uis-rnn and speaker embedding by vgg-speaker-recognition by taylorlu](https://github.com/taylorlu/Speaker-Diarization)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nJiZwrIPqPK",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#◢ Verify Correct Runtime Settings\n",
        "\n",
        "**<font color='#FF000'> IMPORTANT </font>**\n",
        "\n",
        "In the \"Runtime\" menu for the notebook window, select \"Change runtime type.\" Ensure that the following are selected:\n",
        "* Runtime Type = Python 3\n",
        "* Hardware Accelerator = GPU\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bg1lRc5VQG8f",
        "colab_type": "text"
      },
      "source": [
        "#◢ Git clone and install Mevon-AI Speech Emotion Recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTWK6HAPPL43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/SuyashMore/MevonAI-Speech-Emotion-Recognition.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNOzO-tyQzdL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd MevonAI-Speech-Emotion-Recognition/src"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vFfeI0IQYhD",
        "colab_type": "text"
      },
      "source": [
        "#◢ Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9zJdxSLY_rr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!chmod +x setup.sh\n",
        "!./setup.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eam-QOmHajCk",
        "colab_type": "text"
      },
      "source": [
        "#◢ Instructions\n",
        "\n",
        "## Add Audio Files\n",
        "You can add audio files in any language inside input/ folder.\n",
        "\n",
        "For eg. currently, there are 3 folders for 3 different Employees inside the input/ directory. \n",
        "Each folder contains 1 audio file of conversation between that employee with a customer. You can add many more files in each of the employee's folder. \n",
        "\n",
        "If you have 5 employees, then create 5 folders inside the **input/** directory. Then add audio files of conversation with customer of each employee in the respective folders.\n",
        "\n",
        "## Run Mevon_AI\n",
        "Demo for running the main program is given in the next section. \n",
        "\n",
        "## Diarization Output\n",
        "Since each audio file has 2 speakers: customer and employee of the customer care call center, we split the audio file into 2 such that one audio file contains the audio of customer and other contains the audio of employee.\n",
        "\n",
        "These splitted audio files are stored in **output**/ folder\n",
        "\n",
        "##Predicted Emotions\n",
        "The audio file of each customer is analysed by the CNN model and a **.csv** file is generated which contains the predicted emotion \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXB2kKqRZN-Q",
        "colab_type": "text"
      },
      "source": [
        "#◢ Recognize Emotions!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXD8AbtrZgqY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rBWrBWlW9Jd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 speechEmotionRecognition.py"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}